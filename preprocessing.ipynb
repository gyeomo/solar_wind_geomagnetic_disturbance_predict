{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn')\n",
    "sns.set(font_scale=2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = pd.read_csv(\"y_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_data = pd.read_csv(\"ace_1999.csv\", names=['year', 'doy' ,'hr', 'min', 'Np', 'Tp', 'Vp' ,'B_gsm_x' ,'B_gsm_y', 'B_gsm_z', 'Bt'],sep = '\\s+')\n",
    "x1_data = x1_data.append(pd.read_csv(\"ace_2000.csv\", names=['year', 'doy' ,'hr', 'min', 'Np', 'Tp', 'Vp' ,'B_gsm_x' ,'B_gsm_y', 'B_gsm_z', 'Bt'],sep = '\\s+'))\n",
    "x1_data = x1_data.append(pd.read_csv(\"ace_2001.csv\", names=['year', 'doy' ,'hr', 'min', 'Np', 'Tp', 'Vp' ,'B_gsm_x' ,'B_gsm_y', 'B_gsm_z', 'Bt'],sep = '\\s+'))\n",
    "x1_data = x1_data.append(pd.read_csv(\"ace_2002.csv\", names=['year', 'doy' ,'hr', 'min', 'Np', 'Tp', 'Vp' ,'B_gsm_x' ,'B_gsm_y', 'B_gsm_z', 'Bt'],sep = '\\s+'))\n",
    "x1_data = x1_data.append(pd.read_csv(\"ace_2003.csv\", names=['year', 'doy' ,'hr', 'min', 'Np', 'Tp', 'Vp' ,'B_gsm_x' ,'B_gsm_y', 'B_gsm_z', 'Bt'],sep = '\\s+'))\n",
    "x1_data = x1_data.append(pd.read_csv(\"ace_2004.csv\", names=['year', 'doy' ,'hr', 'min', 'Np', 'Tp', 'Vp' ,'B_gsm_x' ,'B_gsm_y', 'B_gsm_z', 'Bt'],sep = '\\s+'))\n",
    "x1_data = x1_data.append(pd.read_csv(\"ace_2005.csv\", names=['year', 'doy' ,'hr', 'min', 'Np', 'Tp', 'Vp' ,'B_gsm_x' ,'B_gsm_y', 'B_gsm_z', 'Bt'],sep = '\\s+'))\n",
    "x1_data = x1_data.append(pd.read_csv(\"ace_2006.csv\", names=['year', 'doy' ,'hr', 'min', 'Np', 'Tp', 'Vp' ,'B_gsm_x' ,'B_gsm_y', 'B_gsm_z', 'Bt'],sep = '\\s+'))\n",
    "x1_data = x1_data.append(pd.read_csv(\"ace_2007.csv\", names=['year', 'doy' ,'hr', 'min', 'Np', 'Tp', 'Vp' ,'B_gsm_x' ,'B_gsm_y', 'B_gsm_z', 'Bt'],sep = '\\s+'))\n",
    "x1_data = x1_data.append(pd.read_csv(\"ace_2008.csv\", names=['year', 'doy' ,'hr', 'min', 'Np', 'Tp', 'Vp' ,'B_gsm_x' ,'B_gsm_y', 'B_gsm_z', 'Bt'],sep = '\\s+'))\n",
    "x1_data = x1_data.append(pd.read_csv(\"ace_2009.csv\", names=['year', 'doy' ,'hr', 'min', 'Np', 'Tp', 'Vp' ,'B_gsm_x' ,'B_gsm_y', 'B_gsm_z', 'Bt'],sep = '\\s+'))\n",
    "x1_data = x1_data.append(pd.read_csv(\"ace_2010.csv\", names=['year', 'doy' ,'hr', 'min', 'Np', 'Tp', 'Vp' ,'B_gsm_x' ,'B_gsm_y', 'B_gsm_z', 'Bt'],sep = '\\s+'))\n",
    "x1_data = x1_data.append(pd.read_csv(\"ace_2011.csv\", names=['year', 'doy' ,'hr', 'min', 'Np', 'Tp', 'Vp' ,'B_gsm_x' ,'B_gsm_y', 'B_gsm_z', 'Bt'],sep = '\\s+'))\n",
    "x1_data = x1_data.append(pd.read_csv(\"ace_2012.csv\", names=['year', 'doy' ,'hr', 'min', 'Np', 'Tp', 'Vp' ,'B_gsm_x' ,'B_gsm_y', 'B_gsm_z', 'Bt'],sep = '\\s+'))\n",
    "x1_data = x1_data.append(pd.read_csv(\"ace_2013.csv\", names=['year', 'doy' ,'hr', 'min', 'Np', 'Tp', 'Vp' ,'B_gsm_x' ,'B_gsm_y', 'B_gsm_z', 'Bt'],sep = '\\s+'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "x1_data['Np'] = x1_data['Np'].apply(lambda x: np.nan if x < 0 else x)\n",
    "x1_data['Tp'] = x1_data['Tp'].apply(lambda x: np.nan if x < 0 else x)\n",
    "x1_data['Vp'] = x1_data['Vp'].apply(lambda x: np.nan if x < 0 else x)\n",
    "x1_data['B_gsm_x'] = x1_data['B_gsm_x'].apply(lambda x: np.nan if x < -999 else x)\n",
    "x1_data['B_gsm_y'] = x1_data['B_gsm_y'].apply(lambda x: np.nan if x < -999 else x)\n",
    "x1_data['B_gsm_z'] = x1_data['B_gsm_z'].apply(lambda x: np.nan if x < -999 else x)\n",
    "x1_data['Bt'] = x1_data['Bt'].apply(lambda x: np.nan if x < -999 else x)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yd_data=y_data\n",
    "y1_data = yd_data.drop(['date'], axis='columns')\n",
    "\n",
    "ys_data = pd.Series()\n",
    "for i in range(0,y1_data.shape[0]):\n",
    "    ys_data = ys_data.append(y1_data.loc[i])\n",
    "\n",
    "#Y_train = ys_data[0:2000]\n",
    "#Y_test = ys_data[2000:2920]\n",
    "ys_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_data = pd.DataFrame(columns=['year', 'doy' ,'hr', 'min', 'Np', 'Tp', 'Vp' ,'B_gsm_x' ,'B_gsm_y', 'B_gsm_z', 'Bt','kp'])\n",
    "flag = 0\n",
    "count = -1\n",
    "for k in range(1999, 2014):\n",
    "    xy_data = x1_data.loc[(x1_data['year']==k),:]\n",
    "    r = 366\n",
    "    if (k == 2000) | (k == 2004) | (k == 2008) | (k == 2012):\n",
    "        r = 367\n",
    "    for j in range(1,r):\n",
    "        x1_doy1 = xy_data.loc[(xy_data['doy']==j),:]\n",
    "        for i in range(0,23,3):\n",
    "            x1_train = x1_doy1.loc[((x1_doy1['hr']==i)|(x1_doy1['hr']==i+1)|(x1_doy1['hr']==i+2))]\n",
    "            count = count + 1\n",
    "            if count% 500 == 0:\n",
    "                print(count)\n",
    "            x1_train['kp'] = ys_data.iloc[count]\n",
    "            make_data = make_data.append(x1_train,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_data.to_csv(\"make_data.csv\",header=False, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_data = pd.read_csv(\"make_data.csv\", names=['year', 'doy' ,'hr', 'min', 'Np', 'Tp', 'Vp' ,'B_gsm_x' ,'B_gsm_y', 'B_gsm_z', 'Bt','kp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "make_data['Np'] = make_data['Np'].apply(lambda x: np.nan if x < 0 else x)\n",
    "make_data['Tp'] = make_data['Tp'].apply(lambda x: np.nan if x < 0 else x)\n",
    "make_data['Vp'] = make_data['Vp'].apply(lambda x: np.nan if x < 0 else x)\n",
    "make_data['B_gsm_x'] = make_data['B_gsm_x'].apply(lambda x: np.nan if x < -999 else x)\n",
    "make_data['B_gsm_y'] = make_data['B_gsm_y'].apply(lambda x: np.nan if x < -999 else x)\n",
    "make_data['B_gsm_z'] = make_data['B_gsm_z'].apply(lambda x: np.nan if x < -999 else x)\n",
    "make_data['Bt'] = make_data['Bt'].apply(lambda x: np.nan if x < -999 else x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_data = make_data.loc[make_data.Np.notnull() & \n",
    "                           make_data.Tp.notnull()& \n",
    "                           make_data.Vp.notnull()&\n",
    "                          make_data.B_gsm_x.notnull()&\n",
    "                          make_data.B_gsm_y.notnull()&\n",
    "                          make_data.B_gsm_z.notnull()&\n",
    "                          make_data.Bt.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_data_Np = make_data.loc[test_data.Np.isnull()]\n",
    "non_data_Tp = make_data.loc[test_data.Tp.isnull()]\n",
    "non_data_Vp = make_data.loc[test_data.Vp.isnull()]\n",
    "non_data_B_gsm_x = make_data.loc[test_data.B_gsm_x.isnull()]\n",
    "non_data_B_gsm_y = make_data.loc[test_data.B_gsm_y.isnull()]\n",
    "non_data_B_gsm_z = make_data.loc[test_data.B_gsm_z.isnull()]\n",
    "non_data_Bt = make_data.loc[test_data.Bt.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "year          0\n",
       "doy           0\n",
       "hr            0\n",
       "min           0\n",
       "Np         3917\n",
       "Tp         3751\n",
       "Vp         3682\n",
       "B_gsm_x    4423\n",
       "B_gsm_y    4422\n",
       "B_gsm_z    4422\n",
       "Bt         4422\n",
       "kp            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_data_B_gsm_x.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics.scorer import make_scorer\n",
    "\n",
    "def custom_loss(y_true, y_pred):\n",
    "    return mean_squared_error(y_true,y_pred,sample_weight = y_true)\n",
    "def rmsew_loss(y_true, y_pred):\n",
    "    value = mean_squared_error(y_true,y_pred)\n",
    "    if value < 0 :\n",
    "        value = -value\n",
    "    return value\n",
    "scorer = make_scorer(rmsew_loss, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.8493485593779404"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from lightgbm import LGBMRegressor\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    value_data[['Tp','Vp','B_gsm_x','B_gsm_y','B_gsm_z','Bt','kp']],\n",
    "    value_data['Np'], test_size=0.2, random_state=321)\n",
    "lbm = LGBMRegressor(objective='regression',bagging_fraction =0.7944444444444444, \n",
    "                        bagging_freq = 7, learning_rate = 0.2641670111852695,\n",
    "                        max_depth = 3, min_child_samples = 158,\n",
    "                        min_child_weight=0.01, min_data_in_leaf = 60,\n",
    "                        n_estimators = 204, reg_alpha = 0.3833333333333333,\n",
    "                        reg_lambda =0.8555555555555555, subsample= 0.2371603301759982, n_jobs = 4)\n",
    "lbm.fit((X_train), y_train)\n",
    "ypred = lbm.predict((X_test))\n",
    "np.sqrt(rmsew_loss(y_test, ypred))\n",
    "#88.08141456344133\n",
    "#82.52446622179468"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2795445,)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred = lbm.predict((non_data_Np[['Tp','Vp','B_gsm_x','B_gsm_y','B_gsm_z','Bt','kp']]))\n",
    "ypred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump = test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump.Np.loc[dump.Np.isnull()] = ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "year       0\n",
       "doy        0\n",
       "hr         0\n",
       "min        0\n",
       "Np         0\n",
       "Tp         0\n",
       "Vp         0\n",
       "B_gsm_x    0\n",
       "B_gsm_y    0\n",
       "B_gsm_z    0\n",
       "Bt         0\n",
       "kp         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump.to_csv(\"x_preprocessing.csv\",header=False, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:  7.3min\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed: 47.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 2.9002334372270577\n",
      "Best params: {'bagging_fraction': 0.6, 'bagging_freq': 3, 'learning_rate': 0.5931321619603104, 'max_depth': 10, 'min_child_samples': 228, 'min_child_weight': 1000.0, 'min_data_in_leaf': 97, 'n_estimators': 212, 'reg_alpha': 0.978553714145801, 'reg_lambda': 0.8482288126171406, 'subsample': 0.7832057344327898}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from lightgbm import LGBMRegressor\n",
    "import scipy as sp\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import randint as sp_randint\n",
    "from scipy.stats import uniform as sp_uniform\n",
    "clf_lgb =  LGBMRegressor(objective='regression',n_jobs = 4)\n",
    "               #huber\n",
    "param_dist = {'n_estimators': stats.randint(150, 1000),\n",
    "              'min_child_samples': sp_randint(100, 500),\n",
    "              'min_child_weight': [1e-5, 1e-3, 1e-2, 1e-1, 1, 1e1, 1e2, 1e3, 1e4],\n",
    "              'subsample': sp_uniform(loc=0.2, scale=0.8),\n",
    "              'reg_alpha': stats.uniform(0, 1.2),\n",
    "              'reg_lambda': stats.uniform(0, 1.2),\n",
    "              'min_data_in_leaf': stats.randint(10, 100),\n",
    "              'bagging_freq': [3, 4, 5, 6, 7,8,9],\n",
    "              'bagging_fraction': np.linspace(0.6, 0.95, 10),\n",
    "              'learning_rate': stats.uniform(0.001, 0.6),\n",
    "              'max_depth': [3, 4, 5, 6, 7, 8, 9,10,11,12,13]\n",
    "             }\n",
    "clf = RandomizedSearchCV(clf_lgb, param_distributions = param_dist, n_iter = 10, scoring = scorer, cv=5, error_score = 0, verbose = 5, n_jobs = 4, random_state=42)\n",
    "clf.fit(np.array(value_data['kp']).reshape(-1,1),value_data['Bt'])\n",
    "\n",
    "best_score = clf.best_score_\n",
    "best_params = clf.best_params_\n",
    "print(\"Best score: {}\".format(np.sqrt(-best_score)))\n",
    "print(\"Best params: {}\".format(best_params))\n",
    "################### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:  7.1min\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed: 48.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 3.67241225677772\n",
      "Best params: {'bagging_fraction': 0.6, 'bagging_freq': 3, 'learning_rate': 0.5931321619603104, 'max_depth': 10, 'min_child_samples': 228, 'min_child_weight': 1000.0, 'min_data_in_leaf': 97, 'n_estimators': 212, 'reg_alpha': 0.978553714145801, 'reg_lambda': 0.8482288126171406, 'subsample': 0.7832057344327898}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from lightgbm import LGBMRegressor\n",
    "import scipy as sp\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import randint as sp_randint\n",
    "from scipy.stats import uniform as sp_uniform\n",
    "clf_lgb =  LGBMRegressor(objective='regression',n_jobs = 4)\n",
    "               #huber\n",
    "param_dist = {'n_estimators': stats.randint(150, 1000),\n",
    "              'min_child_samples': sp_randint(100, 500),\n",
    "              'min_child_weight': [1e-5, 1e-3, 1e-2, 1e-1, 1, 1e1, 1e2, 1e3, 1e4],\n",
    "              'subsample': sp_uniform(loc=0.2, scale=0.8),\n",
    "              'reg_alpha': stats.uniform(0, 1.2),\n",
    "              'reg_lambda': stats.uniform(0, 1.2),\n",
    "              'min_data_in_leaf': stats.randint(10, 100),\n",
    "              'bagging_freq': [3, 4, 5, 6, 7,8,9],\n",
    "              'bagging_fraction': np.linspace(0.6, 0.95, 10),\n",
    "              'learning_rate': stats.uniform(0.001, 0.6),\n",
    "              'max_depth': [3, 4, 5, 6, 7, 8, 9,10,11,12,13]\n",
    "             }\n",
    "clf = RandomizedSearchCV(clf_lgb, param_distributions = param_dist, n_iter = 10, scoring = scorer, cv=5, error_score = 0, verbose = 5, n_jobs = 4, random_state=42)\n",
    "clf.fit(np.array(value_data['kp']).reshape(-1,1),value_data['B_gsm_z'])\n",
    "\n",
    "best_score = clf.best_score_\n",
    "best_params = clf.best_params_\n",
    "print(\"Best score: {}\".format(np.sqrt(-best_score)))\n",
    "print(\"Best params: {}\".format(best_params))\n",
    "################### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:  7.1min\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed: 48.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 4.468603805202551\n",
      "Best params: {'bagging_fraction': 0.6, 'bagging_freq': 3, 'learning_rate': 0.5931321619603104, 'max_depth': 10, 'min_child_samples': 228, 'min_child_weight': 1000.0, 'min_data_in_leaf': 97, 'n_estimators': 212, 'reg_alpha': 0.978553714145801, 'reg_lambda': 0.8482288126171406, 'subsample': 0.7832057344327898}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from lightgbm import LGBMRegressor\n",
    "import scipy as sp\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import randint as sp_randint\n",
    "from scipy.stats import uniform as sp_uniform\n",
    "clf_lgb =  LGBMRegressor(objective='regression',n_jobs = 4)\n",
    "               #huber\n",
    "param_dist = {'n_estimators': stats.randint(150, 1000),\n",
    "              'min_child_samples': sp_randint(100, 500),\n",
    "              'min_child_weight': [1e-5, 1e-3, 1e-2, 1e-1, 1, 1e1, 1e2, 1e3, 1e4],\n",
    "              'subsample': sp_uniform(loc=0.2, scale=0.8),\n",
    "              'reg_alpha': stats.uniform(0, 1.2),\n",
    "              'reg_lambda': stats.uniform(0, 1.2),\n",
    "              'min_data_in_leaf': stats.randint(10, 100),\n",
    "              'bagging_freq': [3, 4, 5, 6, 7,8,9],\n",
    "              'bagging_fraction': np.linspace(0.6, 0.95, 10),\n",
    "              'learning_rate': stats.uniform(0.001, 0.6),\n",
    "              'max_depth': [3, 4, 5, 6, 7, 8, 9,10,11,12,13]\n",
    "             }\n",
    "clf = RandomizedSearchCV(clf_lgb, param_distributions = param_dist, n_iter = 10, scoring = scorer, cv=5, error_score = 0, verbose = 5, n_jobs = 4, random_state=42)\n",
    "clf.fit(np.array(value_data['kp']).reshape(-1,1),value_data['B_gsm_y'])\n",
    "\n",
    "best_score = clf.best_score_\n",
    "best_params = clf.best_params_\n",
    "print(\"Best score: {}\".format(np.sqrt(-best_score)))\n",
    "print(\"Best params: {}\".format(best_params))\n",
    "################### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:  7.1min\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed: 47.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 4.04727854711519\n",
      "Best params: {'bagging_fraction': 0.8722222222222222, 'bagging_freq': 5, 'learning_rate': 0.013350696577481468, 'max_depth': 4, 'min_child_samples': 443, 'min_child_weight': 10.0, 'min_data_in_leaf': 11, 'n_estimators': 341, 'reg_alpha': 1.190653871149461, 'reg_lambda': 0.7409778115532598, 'subsample': 0.6893225283906248}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from lightgbm import LGBMRegressor\n",
    "import scipy as sp\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import randint as sp_randint\n",
    "from scipy.stats import uniform as sp_uniform\n",
    "clf_lgb =  LGBMRegressor(objective='regression',n_jobs = 4)\n",
    "               #huber\n",
    "param_dist = {'n_estimators': stats.randint(150, 1000),\n",
    "              'min_child_samples': sp_randint(100, 500),\n",
    "              'min_child_weight': [1e-5, 1e-3, 1e-2, 1e-1, 1, 1e1, 1e2, 1e3, 1e4],\n",
    "              'subsample': sp_uniform(loc=0.2, scale=0.8),\n",
    "              'reg_alpha': stats.uniform(0, 1.2),\n",
    "              'reg_lambda': stats.uniform(0, 1.2),\n",
    "              'min_data_in_leaf': stats.randint(10, 100),\n",
    "              'bagging_freq': [3, 4, 5, 6, 7,8,9],\n",
    "              'bagging_fraction': np.linspace(0.6, 0.95, 10),\n",
    "              'learning_rate': stats.uniform(0.001, 0.6),\n",
    "              'max_depth': [3, 4, 5, 6, 7, 8, 9,10,11,12,13]\n",
    "             }\n",
    "clf = RandomizedSearchCV(clf_lgb, param_distributions = param_dist, n_iter = 10, scoring = scorer, cv=5, error_score = 0, verbose = 5, n_jobs = 4, random_state=42)\n",
    "clf.fit(np.array(value_data['kp']).reshape(-1,1),value_data['B_gsm_x'])\n",
    "\n",
    "best_score = clf.best_score_\n",
    "best_params = clf.best_params_\n",
    "print(\"Best score: {}\".format(np.sqrt(-best_score)))\n",
    "print(\"Best params: {}\".format(best_params))\n",
    "################### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
