{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = pd.read_csv(\"y_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_data = pd.read_csv(\"ace_1999.csv\", names=['year', 'doy' ,'hr', 'min', 'Np', 'Tp', 'Vp' ,'B_gsm_x' ,'B_gsm_y', 'B_gsm_z', 'Bt'],sep = '\\s+')\n",
    "x1_data = x1_data.append(pd.read_csv(\"ace_2000.csv\", names=['year', 'doy' ,'hr', 'min', 'Np', 'Tp', 'Vp' ,'B_gsm_x' ,'B_gsm_y', 'B_gsm_z', 'Bt'],sep = '\\s+'))\n",
    "x1_data = x1_data.append(pd.read_csv(\"ace_2001.csv\", names=['year', 'doy' ,'hr', 'min', 'Np', 'Tp', 'Vp' ,'B_gsm_x' ,'B_gsm_y', 'B_gsm_z', 'Bt'],sep = '\\s+'))\n",
    "x1_data = x1_data.append(pd.read_csv(\"ace_2002.csv\", names=['year', 'doy' ,'hr', 'min', 'Np', 'Tp', 'Vp' ,'B_gsm_x' ,'B_gsm_y', 'B_gsm_z', 'Bt'],sep = '\\s+'))\n",
    "x1_data = x1_data.append(pd.read_csv(\"ace_2003.csv\", names=['year', 'doy' ,'hr', 'min', 'Np', 'Tp', 'Vp' ,'B_gsm_x' ,'B_gsm_y', 'B_gsm_z', 'Bt'],sep = '\\s+'))\n",
    "x1_data = x1_data.append(pd.read_csv(\"ace_2004.csv\", names=['year', 'doy' ,'hr', 'min', 'Np', 'Tp', 'Vp' ,'B_gsm_x' ,'B_gsm_y', 'B_gsm_z', 'Bt'],sep = '\\s+'))\n",
    "x1_data = x1_data.append(pd.read_csv(\"ace_2005.csv\", names=['year', 'doy' ,'hr', 'min', 'Np', 'Tp', 'Vp' ,'B_gsm_x' ,'B_gsm_y', 'B_gsm_z', 'Bt'],sep = '\\s+'))\n",
    "x1_data = x1_data.append(pd.read_csv(\"ace_2006.csv\", names=['year', 'doy' ,'hr', 'min', 'Np', 'Tp', 'Vp' ,'B_gsm_x' ,'B_gsm_y', 'B_gsm_z', 'Bt'],sep = '\\s+'))\n",
    "x1_data = x1_data.append(pd.read_csv(\"ace_2007.csv\", names=['year', 'doy' ,'hr', 'min', 'Np', 'Tp', 'Vp' ,'B_gsm_x' ,'B_gsm_y', 'B_gsm_z', 'Bt'],sep = '\\s+'))\n",
    "x1_data = x1_data.append(pd.read_csv(\"ace_2008.csv\", names=['year', 'doy' ,'hr', 'min', 'Np', 'Tp', 'Vp' ,'B_gsm_x' ,'B_gsm_y', 'B_gsm_z', 'Bt'],sep = '\\s+'))\n",
    "x1_data = x1_data.append(pd.read_csv(\"ace_2009.csv\", names=['year', 'doy' ,'hr', 'min', 'Np', 'Tp', 'Vp' ,'B_gsm_x' ,'B_gsm_y', 'B_gsm_z', 'Bt'],sep = '\\s+'))\n",
    "x1_data = x1_data.append(pd.read_csv(\"ace_2010.csv\", names=['year', 'doy' ,'hr', 'min', 'Np', 'Tp', 'Vp' ,'B_gsm_x' ,'B_gsm_y', 'B_gsm_z', 'Bt'],sep = '\\s+'))\n",
    "x1_data = x1_data.append(pd.read_csv(\"ace_2011.csv\", names=['year', 'doy' ,'hr', 'min', 'Np', 'Tp', 'Vp' ,'B_gsm_x' ,'B_gsm_y', 'B_gsm_z', 'Bt'],sep = '\\s+'))\n",
    "x1_data = x1_data.append(pd.read_csv(\"ace_2012.csv\", names=['year', 'doy' ,'hr', 'min', 'Np', 'Tp', 'Vp' ,'B_gsm_x' ,'B_gsm_y', 'B_gsm_z', 'Bt'],sep = '\\s+'))\n",
    "x1_data = x1_data.append(pd.read_csv(\"ace_2013.csv\", names=['year', 'doy' ,'hr', 'min', 'Np', 'Tp', 'Vp' ,'B_gsm_x' ,'B_gsm_y', 'B_gsm_z', 'Bt'],sep = '\\s+'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_data = pd.read_csv(\"x_preprocessing.csv\", names=['year', 'doy' ,'hr', 'min', 'Np', 'Tp', 'Vp' ,'B_gsm_x' ,'B_gsm_y', 'B_gsm_z', 'Bt','kp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_data = x1_data.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>doy</th>\n",
       "      <th>hr</th>\n",
       "      <th>min</th>\n",
       "      <th>Np</th>\n",
       "      <th>Tp</th>\n",
       "      <th>Vp</th>\n",
       "      <th>B_gsm_x</th>\n",
       "      <th>B_gsm_y</th>\n",
       "      <th>B_gsm_z</th>\n",
       "      <th>Bt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1999</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.149000</td>\n",
       "      <td>92352.000000</td>\n",
       "      <td>406.000000</td>\n",
       "      <td>-2.174</td>\n",
       "      <td>-2.598</td>\n",
       "      <td>5.550</td>\n",
       "      <td>6.630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1999</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.998000</td>\n",
       "      <td>85859.000000</td>\n",
       "      <td>419.120000</td>\n",
       "      <td>-1.245</td>\n",
       "      <td>-0.140</td>\n",
       "      <td>6.558</td>\n",
       "      <td>6.796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1999</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6.211000</td>\n",
       "      <td>81547.000000</td>\n",
       "      <td>411.990000</td>\n",
       "      <td>-2.003</td>\n",
       "      <td>-1.198</td>\n",
       "      <td>6.306</td>\n",
       "      <td>6.802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1999</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6.680000</td>\n",
       "      <td>72308.000000</td>\n",
       "      <td>405.250000</td>\n",
       "      <td>-3.093</td>\n",
       "      <td>-2.483</td>\n",
       "      <td>5.545</td>\n",
       "      <td>6.854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1999</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>9.285269</td>\n",
       "      <td>33117.345851</td>\n",
       "      <td>406.631849</td>\n",
       "      <td>-3.009</td>\n",
       "      <td>-1.500</td>\n",
       "      <td>5.908</td>\n",
       "      <td>6.842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7429499</td>\n",
       "      <td>2013</td>\n",
       "      <td>365</td>\n",
       "      <td>23</td>\n",
       "      <td>55</td>\n",
       "      <td>6.073752</td>\n",
       "      <td>64605.000000</td>\n",
       "      <td>381.590000</td>\n",
       "      <td>0.086</td>\n",
       "      <td>5.690</td>\n",
       "      <td>-0.674</td>\n",
       "      <td>5.734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7429500</td>\n",
       "      <td>2013</td>\n",
       "      <td>365</td>\n",
       "      <td>23</td>\n",
       "      <td>56</td>\n",
       "      <td>5.937343</td>\n",
       "      <td>68702.000000</td>\n",
       "      <td>381.420000</td>\n",
       "      <td>0.360</td>\n",
       "      <td>5.675</td>\n",
       "      <td>-0.134</td>\n",
       "      <td>5.695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7429501</td>\n",
       "      <td>2013</td>\n",
       "      <td>365</td>\n",
       "      <td>23</td>\n",
       "      <td>57</td>\n",
       "      <td>5.547756</td>\n",
       "      <td>70184.000000</td>\n",
       "      <td>380.460000</td>\n",
       "      <td>-1.113</td>\n",
       "      <td>5.470</td>\n",
       "      <td>-0.864</td>\n",
       "      <td>5.706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7429502</td>\n",
       "      <td>2013</td>\n",
       "      <td>365</td>\n",
       "      <td>23</td>\n",
       "      <td>58</td>\n",
       "      <td>5.466994</td>\n",
       "      <td>68187.000000</td>\n",
       "      <td>374.230000</td>\n",
       "      <td>-1.486</td>\n",
       "      <td>5.359</td>\n",
       "      <td>-0.857</td>\n",
       "      <td>5.657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7429503</td>\n",
       "      <td>2013</td>\n",
       "      <td>365</td>\n",
       "      <td>23</td>\n",
       "      <td>59</td>\n",
       "      <td>8.282996</td>\n",
       "      <td>64837.000000</td>\n",
       "      <td>406.903195</td>\n",
       "      <td>-0.475</td>\n",
       "      <td>5.646</td>\n",
       "      <td>-0.295</td>\n",
       "      <td>5.678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7429504 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         year  doy  hr  min        Np            Tp          Vp  B_gsm_x  \\\n",
       "0        1999    1   0    0  7.149000  92352.000000  406.000000   -2.174   \n",
       "1        1999    1   0    1  5.998000  85859.000000  419.120000   -1.245   \n",
       "2        1999    1   0    2  6.211000  81547.000000  411.990000   -2.003   \n",
       "3        1999    1   0    3  6.680000  72308.000000  405.250000   -3.093   \n",
       "4        1999    1   0    4  9.285269  33117.345851  406.631849   -3.009   \n",
       "...       ...  ...  ..  ...       ...           ...         ...      ...   \n",
       "7429499  2013  365  23   55  6.073752  64605.000000  381.590000    0.086   \n",
       "7429500  2013  365  23   56  5.937343  68702.000000  381.420000    0.360   \n",
       "7429501  2013  365  23   57  5.547756  70184.000000  380.460000   -1.113   \n",
       "7429502  2013  365  23   58  5.466994  68187.000000  374.230000   -1.486   \n",
       "7429503  2013  365  23   59  8.282996  64837.000000  406.903195   -0.475   \n",
       "\n",
       "         B_gsm_y  B_gsm_z     Bt  \n",
       "0         -2.598    5.550  6.630  \n",
       "1         -0.140    6.558  6.796  \n",
       "2         -1.198    6.306  6.802  \n",
       "3         -2.483    5.545  6.854  \n",
       "4         -1.500    5.908  6.842  \n",
       "...          ...      ...    ...  \n",
       "7429499    5.690   -0.674  5.734  \n",
       "7429500    5.675   -0.134  5.695  \n",
       "7429501    5.470   -0.864  5.706  \n",
       "7429502    5.359   -0.857  5.657  \n",
       "7429503    5.646   -0.295  5.678  \n",
       "\n",
       "[7429504 rows x 11 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1_data = x1_data.drop(['kp'], 1)\n",
    "x1_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.DataFrame(columns=['year', 'doy' ,'hr', 'min', 'Np', 'Tp', 'Vp' ,'B_gsm_x' ,'B_gsm_y', 'B_gsm_z', 'Bt'])\n",
    "for k in range(1999, 2014):\n",
    "    xy_data = x1_data.loc[(x1_data['year']==k),:]\n",
    "    r = 366\n",
    "    if (k == 2000) | (k == 2004) | (k == 2008) | (k == 2012):\n",
    "        r = 367\n",
    "    for j in range(1,r):\n",
    "        x1_doy1 = xy_data.loc[(xy_data['doy']==j),:]\n",
    "        for i in range(0,23,3):\n",
    "            x1_train = x1_doy1.loc[((x1_doy1['hr']==i)|(x1_doy1['hr']==i+1)|(x1_doy1['hr']==i+2))].median()\n",
    "            test_data = test_data.append(x1_train,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43832, 7)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data = test_data.drop(['year','doy','hr','min'], axis='columns')\n",
    "x_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43832,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yd_data=y_data\n",
    "y1_data = yd_data.drop(['date'], axis='columns')\n",
    "\n",
    "ys_data = pd.Series()\n",
    "for i in range(0,y1_data.shape[0]):\n",
    "    ys_data = ys_data.append(y1_data.loc[i])\n",
    "\n",
    "#Y_train = ys_data[0:2000]\n",
    "#Y_test = ys_data[2000:2920]\n",
    "ys_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics.scorer import make_scorer\n",
    "\n",
    "def custom_loss(y_true, y_pred):\n",
    "    return mean_squared_error(y_true,y_pred,sample_weight = y_true)\n",
    "def rmsew_loss(y_true, y_pred):\n",
    "    value = mean_squared_error(y_true,y_pred,sample_weight = y_true)\n",
    "    if value < 0 :\n",
    "        value = -value\n",
    "    return value\n",
    "scorer = make_scorer(custom_loss, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=4)]: Done  64 tasks      | elapsed: 20.0min\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed: 50.0min\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed: 66.4min finished\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.8565792213874298\n",
      "Best params: {'colsample_bytree': 0.8, 'gamma': 0.5063470372789738, 'learning_rate': 0.04813501017161418, 'max_depth': 9, 'min_child_weight': 8, 'n_estimators': 954, 'reg_alpha': 36.580308916903206, 'reg_lambda': 31.977873567760657, 'subsample': 0.7}\n"
     ]
    }
   ],
   "source": [
    "################### test\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import scipy as sp\n",
    "import scipy.stats as stats\n",
    "clf_xgb = xgb.XGBRegressor(objective = 'reg:linear' , n_jobs=4)\n",
    "               \n",
    "param_dist = {'n_estimators': stats.randint(150, 1500),\n",
    "              'learning_rate': stats.uniform(0.01, 0.6),\n",
    "              'max_depth': [3, 4, 5, 6, 7, 8, 9,10,11,12],\n",
    "              'gamma': stats.uniform(0.01, 1.5),\n",
    "              'reg_lambda': stats.uniform(0.1, 50),\n",
    "              'reg_alpha': stats.uniform(0.1, 50),\n",
    "              'subsample': [0.5,0.6,0.7,0.8,0.9],\n",
    "              'colsample_bytree': [0.5,0.6,0.7,0.8,0.9],\n",
    "              'min_child_weight': stats.randint(1, 12)\n",
    "             }\n",
    "clf = RandomizedSearchCV(clf_xgb, param_distributions = param_dist, n_iter = 40, scoring = scorer, cv=5, error_score = 0, verbose = 5, n_jobs = 4, random_state=42)\n",
    "clf.fit(x_data, ys_data)\n",
    "\n",
    "best_score = clf.best_score_\n",
    "best_params = clf.best_params_\n",
    "print(\"Best score: {}\".format(np.sqrt(-best_score)))\n",
    "print(\"Best params: {}\".format(best_params))\n",
    "################### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "0.9071369444983051\n",
    "{'gamma': 1.0,\n",
    " 'learning_rate': 0.599938531484073,\n",
    " 'max_depth': 3,\n",
    " 'min_child_weight': 3,\n",
    " 'n_estimators': 456,\n",
    " 'reg_lambda': 50.0}\n",
    " #################################\n",
    " Best score: 0.9021296602120604\n",
    "Best params: {'colsample_bytree': 0.85, \n",
    "'gamma': 0.25, 'learning_rate': 0.03787024763199864, \n",
    "'max_depth': 5, 'min_child_weight': 7, 'n_estimators': 478, \n",
    "'reg_lambda': 1.0, 'subsample': 0.5}\n",
    "#####################################\n",
    "Best score: 0.9138719123094308\n",
    "Best params: {'colsample_bytree': 0.8, \n",
    "'gamma': 1.2048144802903493, 'learning_rate': 0.12006087391969827, \n",
    "'max_depth': 7, 'min_child_weight': 5, 'missing': -999, \n",
    "'n_estimators': 252, 'reg_lambda': 22.39163764267956, \n",
    "'silent': 1, 'subsample': 0.8}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "condition : 0.18599999999999986, accuracy: 0.8440628706616763\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_data, ys_data, test_size=0.2, random_state=321)\n",
    "#gbm = xgb.XGBRegressor(objective = 'reg:linear', max_depth=5,reg_alpha=0, reg_lambda=0.1, gamma =1.2, n_estimators=478, learning_rate=0.05,min_child_weight = 7, subsample=0.5, colsample_bytree = 0.85,n_jobs=4).fit(X_train, y_train)\n",
    "gbm = xgb.XGBRegressor(objective = 'reg:linear', max_depth=5,reg_alpha=0, reg_lambda=1, gamma =0.25, n_estimators=478, learning_rate=0.03787024763199864,min_child_weight = 7, subsample=0.5, colsample_bytree = 0.85,n_jobs=4).fit(X_train, y_train)\n",
    "most_small = 1\n",
    "idx = 0\n",
    "for i in np.arange(0.01, 0.5, 0.001):\n",
    "    ypred = gbm.predict(X_test)\n",
    "    ypred = pd.Series(ypred).apply(lambda x: 9 if x >= 9 else x)\n",
    "    ypred = pd.Series(ypred).apply(lambda x: np.ceil(x) if (x-np.trunc(x)) >= i else np.trunc(x))\n",
    "    loss = np.sqrt(custom_loss(y_test, ypred))\n",
    "    if most_small >loss:\n",
    "        most_small = loss\n",
    "        idx = i\n",
    "print(\"condition : {0}, accuracy: {1}\".format(idx,most_small)) \n",
    "#0.9364639307354418 , 0.8828912898006811 ì‹¤ìˆ˜\n",
    "#0.915621364529454 , 0.8845052498640339  ì •ìˆ˜\n",
    "#0.8831629814772876"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.846527492935874"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_data, ys_data, test_size=0.2, random_state=321)\n",
    "#gbm = xgb.XGBRegressor(objective = 'reg:linear', max_depth=5,reg_alpha=0, reg_lambda=0.1, gamma =1.2, n_estimators=478, learning_rate=0.05,min_child_weight = 7, subsample=0.5, colsample_bytree = 0.85,n_jobs=4).fit(X_train, y_train)\n",
    "gbm = xgb.XGBRegressor(objective = 'reg:linear', max_depth=5,reg_alpha=0, reg_lambda=1, gamma =0.25, n_estimators=478, learning_rate=0.03787024763199864,min_child_weight = 7, subsample=0.5, colsample_bytree = 0.85,n_jobs=4).fit(X_train, y_train)\n",
    "ypred = gbm.predict(X_test)\n",
    "ypred = pd.Series(ypred).apply(lambda x: 9 if x >= 9 else x)\n",
    "ypred = pd.Series(ypred).apply(lambda x: np.ceil(x) if (x-np.trunc(x)) >= 0.16 else np.trunc(x))\n",
    "np.sqrt(custom_loss(y_test, ypred))\n",
    "\n",
    "\n",
    "#0.8663260548623326"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2_test = pd.read_csv(\"test_x.csv\",names=['doy' ,'hr', 'min', 'Np', 'Tp', 'Vp' ,'B_gsm_x' ,'B_gsm_y', 'B_gsm_z', 'Bt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2_data = pd.DataFrame(columns=['doy' ,'hr', 'min', 'Np', 'Tp', 'Vp' ,'B_gsm_x' ,'B_gsm_y', 'B_gsm_z', 'Bt'])\n",
    "\n",
    "for j in range(1,366):\n",
    "    x2_doy1 = x2_test.loc[(x2_test['doy']==j),:]\n",
    "    for i in range(0,23,3):\n",
    "        x2_train = x2_doy1.loc[((x2_doy1['hr']==i)|(x2_doy1['hr']==i+1)|(x2_doy1['hr']==i+2))].median()\n",
    "        test2_data = test2_data.append(x2_train,ignore_index=True)\n",
    "x2_data = test2_data.drop(['doy','hr','min'], axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ypred2 = gbm.predict(x2_data)\n",
    "ypred2 = blend_models_predict(x2_data)\n",
    "ypred2 = pd.Series(ypred2).apply(lambda x: 9 if x >= 9 else x)\n",
    "ypred2 = pd.Series(ypred2).apply(lambda x: np.ceil(x) if (x-np.trunc(x)) >= 0.16499999999999987 else np.trunc(x))\n",
    "ypred2 = np.array(ypred2).reshape(-1,8)\n",
    "ypred2 = pd.DataFrame(ypred2, columns = ['kp_0h','kp_3h','kp_6h','kp_9h','kp_12h','kp_15h','kp_18h','kp_21h'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred2.to_csv(\"y.csv\",header=False, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:   34.9s\n",
      "[Parallel(n_jobs=4)]: Done  64 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed:  5.4min\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:  7.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.859934988461581\n",
      "Best params: {'bagging_fraction': 0.7555555555555555, 'bagging_freq': 6, 'learning_rate': 0.02818240586322671, 'max_depth': 12, 'min_child_samples': 349, 'min_child_weight': 0.01, 'min_data_in_leaf': 67, 'n_estimators': 918, 'reg_alpha': 0.647252938080075, 'reg_lambda': 0.8207565232777693, 'subsample': 0.6926809315119311}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from lightgbm import LGBMRegressor\n",
    "import scipy as sp\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import randint as sp_randint\n",
    "from scipy.stats import uniform as sp_uniform\n",
    "clf_lgb =  LGBMRegressor(objective='regression',n_jobs = 4)\n",
    "               #huber\n",
    "param_dist = {'n_estimators': stats.randint(150, 1500),\n",
    "              'min_child_samples': sp_randint(100, 500),\n",
    "              'min_child_weight': [1e-5, 1e-3, 1e-2, 1e-1, 1, 1e1, 1e2, 1e3, 1e4],\n",
    "              'subsample': sp_uniform(loc=0.2, scale=0.8),\n",
    "              'reg_alpha': stats.uniform(0, 1.2),\n",
    "              'reg_lambda': stats.uniform(0, 1.2),\n",
    "              'min_data_in_leaf': stats.randint(10, 100),\n",
    "              'bagging_freq': [3, 4, 5, 6, 7,8,9],\n",
    "              'bagging_fraction': np.linspace(0.6, 0.95, 10),\n",
    "              'learning_rate': stats.uniform(0.001, 0.6),\n",
    "              'max_depth': [3, 4, 5, 6, 7, 8, 9,10,11,12,13]\n",
    "             }\n",
    "clf = RandomizedSearchCV(clf_lgb, param_distributions = param_dist, n_iter = 40, scoring = scorer, cv=5, error_score = 0, verbose = 5, n_jobs = 4, random_state=42)\n",
    "clf.fit(x_data, ys_data)\n",
    "\n",
    "best_score = clf.best_score_\n",
    "best_params = clf.best_params_\n",
    "print(\"Best score: {}\".format(np.sqrt(-best_score)))\n",
    "print(\"Best params: {}\".format(best_params))\n",
    "################### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8701918158063177"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from lightgbm import LGBMRegressor\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_data, ys_data, test_size=0.2, random_state=321)\n",
    "lbm = LGBMRegressor(objective='regression',bagging_fraction =0.7944444444444444, \n",
    "                        bagging_freq = 7, learning_rate = 0.2641670111852695,\n",
    "                        max_depth = 3, min_child_samples = 158,\n",
    "                        min_child_weight=0.01, min_data_in_leaf = 60,\n",
    "                        n_estimators = 204, reg_alpha = 0.3833333333333333,\n",
    "                        reg_lambda =0.8555555555555555, subsample= 0.2371603301759982, n_jobs = 4)\n",
    "lbm.fit(X_train, y_train)\n",
    "ypred = lbm.predict(X_test)\n",
    "ypred = pd.Series(ypred).apply(lambda x: 9 if x >= 9 else x)\n",
    "ypred = pd.Series(ypred).apply(lambda x: np.ceil(x) if (x-np.trunc(x)) >= 0.16 else np.trunc(x))\n",
    "np.sqrt(custom_loss(y_test, ypred))\n",
    "#0.8701918158063177\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Best score: 0.9043611437269182\n",
    "Best params: {'bagging_fraction': 0.7944444444444444, \n",
    "'bagging_freq': 7, 'learning_rate': 0.2641670111852695, \n",
    "'max_depth': 3, 'min_child_samples': 158, \n",
    "'min_child_weight': 0.01, 'min_data_in_leaf': 60, \n",
    "'n_estimators': 204, 'reg_alpha': 0.3833333333333333, \n",
    "'reg_lambda': 0.8555555555555555, 'subsample': 0.2371603301759982}\n",
    "###########################\n",
    "Best score: 0.8996982830079934\n",
    "Best params: {'bagging_fraction': 0.8722222222222222, \n",
    "'bagging_freq': 5, 'learning_rate': 0.013350696577481468, \n",
    "'max_depth': 4, 'min_child_samples': 443, \n",
    "'min_child_weight': 10.0, 'min_data_in_leaf': 20, \n",
    "'n_estimators': 1365, 'reg_alpha': 0.47777777777777775, \n",
    "'reg_lambda': 0.1, 'subsample': 0.4433937943676302}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8605621009721667"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def blend_models_predict(X):\n",
    "    return (0.333 * gbm.predict(X)) + (0.333 * lbm.predict(X)) + (0.334 * stack_gen_model.predict(np.array(X)))\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_data, ys_data, test_size=0.2, random_state=321)\n",
    "from mlxtend.regressor import StackingCVRegressor\n",
    "stack_gen = StackingCVRegressor(regressors=(gbm, lbm),\n",
    "                                meta_regressor=gbm,\n",
    "                                use_features_in_secondary=True)\n",
    "stack_gen_model = stack_gen.fit(np.array(X_train), np.array(y_train))\n",
    "\n",
    "ypred = blend_models_predict(X_test)\n",
    "ypred = pd.Series(ypred).apply(lambda x: 9 if x >= 9 else x)\n",
    "ypred = pd.Series(ypred).apply(lambda x: np.ceil(x) if (x-np.trunc(x)) >= 0.16499999999999987 else np.trunc(x))\n",
    "np.sqrt(custom_loss(y_test, ypred))\n",
    "#0.8643197389341002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "condition : 0.16499999999999987, accuracy: 0.8605621009721667\n"
     ]
    }
   ],
   "source": [
    "most_small = 1\n",
    "for i in np.arange(0.01, 0.5, 0.001):\n",
    "    ypred = blend_models_predict(X_test)\n",
    "    ypred = pd.Series(ypred).apply(lambda x: 9 if x >= 9 else x)\n",
    "    ypred = pd.Series(ypred).apply(lambda x: np.ceil(x) if (x-np.trunc(x)) >= i else np.trunc(x))\n",
    "    loss = np.sqrt(custom_loss(y_test, ypred))\n",
    "    if most_small >loss:\n",
    "        most_small = loss\n",
    "        idx = i\n",
    "print(\"condition : {0}, accuracy: {1}\".format(idx,most_small)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
